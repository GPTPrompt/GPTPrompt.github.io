---
title: "给模型时间“思考”"
description: "给模型时间“思考”"
---
import { Tabs } from 'nextra/components'

如果要求将 17 乘以 28，您可能不会立即知道，但随着时间的推移仍然可以算出来。 同样，模型在尝试立即回答而不是花时间找出答案时会犯更多推理错误。 在给出答案之前询问“思路链”可以帮助模型更可靠地推理出正确答案。

## 策略：指示模型在急于得出结论之前找出自己的解决方案
有时，当我们明确指示模型在得出结论之前从第一原理进行推理时，我们会得到更好的结果。 假设我们想要一个模型来评估学生对数学问题的解决方案。 解决这个问题最明显的方法是简单地询问模型学生的解决方案是否正确。


<Tabs items={['角色: 系统', '角色: 用户','角色: 助手']}>
  <Tabs.Tab>
  确定学生的解决方案是否正确。
  </Tabs.Tab>
  <Tabs.Tab>
  问题陈述：我正在建造一个太阳能发电装置，我需要帮助解决财务问题。
  - 土地成本 100 美元/平方英尺
  - 我可以以 250 美元/平方英尺的价格购买太阳能电池板
  - 我协商了一份维护合同，每年将花费我 10 万美元，每平方英尺额外花费 10 美元
  第一年运营的总成本是多少，与平方英尺数的函数关系。

  学生的解决方案：设 x 为装置的尺寸（以平方英尺为单位）。
  1.土地成本：100x
  2.太阳能电池板成本：250x
  3.维护成本：100,000 + 100x
  总成本：100x + 250x + 100,000 + 100x = 450x + 100,000
 </Tabs.Tab>
 <Tabs.Tab> 该学生的解决方案是正确的。</Tabs.Tab>
</Tabs>
但这位同学的解法其实并不正确！ 我们可以通过提示模型首先生成自己的解决方案来让模型成功注意到这一点。


<Tabs items={['角色: 系统', '角色: 用户','角色: 助手']}>
  <Tabs.Tab>
  首先制定自己的问题解决方案。 然后将你的解决方案与学生的解决方案进行比较，并评估学生的解决方案是否正确。 在你自己完成问题之前，不要决定学生的解决方案是否正确。
  </Tabs.Tab>
  <Tabs.Tab>
    问题陈述：我正在建造一个太阳能发电装置，我需要帮助解决财务问题。
    - 土地成本 100 美元/平方英尺
    - 我可以以 250 美元/平方英尺的价格购买太阳能电池板
    - 我协商了一份维护合同，每年将花费我 10 万美元，每平方英尺额外花费 10 美元
    第一年运营的总成本是多少，与平方英尺数的函数关系。

    学生的解决方案：设 x 为装置的尺寸（以平方英尺为单位）。
    1.土地成本：100x
    2.太阳能电池板成本：250x
    3.维护成本：100,000 + 100x
    总成本：100x + 250x + 100,000 + 100x = 450x + 100,000
 </Tabs.Tab>
 <Tabs.Tab>
  设 x 为安装尺寸（以平方英尺为单位）。
  1.土地成本：100x
  2.太阳能电池板成本：250x
  3.维护成本：100,000 + 10x
  总成本：100x + 250x + 100,000 + 10x = 360x + 100,000

  该学生的解决方案是错误的。 他们在维护成本计算中犯了一个错误，使用了 100x 而不是 10x。 第一年运营的正确总成本是 360x + 100,000。
 </Tabs.Tab>
</Tabs>


## 策略：使用内心独白或一系列查询来隐藏模型的推理过程

前面的策略表明，模型有时在回答特定问题之前详细推理问题很重要。 对于某些应用程序，模型用于得出最终答案的推理过程不适合与用户共享。 例如，在辅导应用程序中，我们可能希望鼓励学生得出自己的答案，但模型关于学生解决方案的推理过程可能会向学生揭示答案。

内心独白是一种可以用来缓解这种情况的策略。 内心独白的想法是指示模型将原本对用户隐藏的部分输出放入结构化格式中，以便于解析它们。 然后，在向用户呈现输出之前，将解析输出并且仅使部分输出可见。

<Tabs items={['角色: 系统', '角色: 用户']}>
  <Tabs.Tab>
    请按照以下步骤回答用户的疑问。

    步骤 1 - 首先找出你自己的问题解决方案。 不要依赖学生的解决方案，因为它可能是不正确的。 将这一步的所有工作用三引号 (""") 括起来。

    第 2 步 - 将您的解决方案与学生的解决方案进行比较，并评估学生的解决方案是否正确。 将这一步的所有工作用三引号 (""") 括起来。

    第 3 步 - 如果学生犯了错误，请确定在不泄露答案的情况下可以给学生什么提示。 将这一步的所有工作用三引号 (""") 括起来。

    步骤 4 - 如果学生犯了错误，请向学生提供上一步的提示（在三重引号之外）。 不要写“步骤 4 - ...”，而写“提示：”。
  </Tabs.Tab>
  <Tabs.Tab>
    问题陈述：{`<插入问题陈述>`}

    学生解决方案：{`<插入学生解决方案>`}
 </Tabs.Tab>
</Tabs>

或者，这可以通过一系列查询来实现，其中除了最后一个查询之外，所有查询的输出都对最终用户隐藏。

首先，我们可以要求模型自己解决问题。 由于这个初始查询不需要学生的解决方案，因此可以省略。 这提供了额外的优势，即模型的解决方案不会因学生尝试的解决方案而产生偏差。

<Tabs items={['用户']}>
  <Tabs.Tab>
    {`<插入问题陈述>`}
  </Tabs.Tab>
</Tabs>
接下来，我们可以让模型使用所有可用信息来评估学生解决方案的正确性。
<Tabs items={['系统','用户']}>
  <Tabs.Tab>
    将您的解决方案与学生的解决方案进行比较，并评估学生的解决方案是否正确。
  </Tabs.Tab>
  <Tabs.Tab>
    问题陈述："""{`<插入问题陈述>`}"""

    您的解决方案："""{`<插入模型生成的解决方案>`}"""

    学生的解决方案："""{`<插入学生的解决方案>`}"""
  </Tabs.Tab>   
</Tabs>

最后，我们可以让模型使用自己的分析来以乐于助人的导师的角色构建回复。
<Tabs items={['系统','用户']}>
  <Tabs.Tab>
    你是一名数学导师。 如果学生犯了错误，请以不透露答案的方式向学生提供提示。 如果学生没有犯错，只需给他们一个鼓励性的评论。
  </Tabs.Tab>
  <Tabs.Tab>
    问题陈述："""{`<插入问题陈述>`}"""

    您的解决方案："""{`<插入模型生成的解决方案>`}"""

    学生的解决方案："""{`<插入学生的解决方案>`}"""

    分析："""{`<插入上一步中模型生成的分析>`}"""
  </Tabs.Tab>   
</Tabs>


## 策略：询问模型在之前的过程中是否遗漏了任何内容

假设我们使用一个模型来列出与特定问题相关的来源的摘录。 列出每个摘录后，模型需要确定是否应该开始编写另一个摘录或者是否应该停止。 如果源文档很大，模型通常会过早停止并且无法列出所有相关摘录。 在这种情况下，通过使用后续查询提示模型查找之前传递中错过的任何摘录，通常可以获得更好的性能。

<Tabs items={['系统','用户','助手','用户']}>
  <Tabs.Tab>
    您将获得一份由三重引号分隔的文档。 你的任务是选择与以下问题相关的摘录：“人工智能历史上发生了哪些重大的范式转变。”

    确保摘录包含解释它们所需的所有相关上下文 - 换句话说，不要提取缺少重要上下文的小片段。 提供 JSON 格式的输出，如下所示：

    {`[{"摘录"："..."}`}，  
    ...  
    {`{"摘录"："..."}]`}
  </Tabs.Tab>
  <Tabs.Tab> 
    {`"""<在此插入文档>"""`}
  </Tabs.Tab>   
  <Tabs.Tab>
  {`[{"excerpt": "模型在此处编写摘录"},`}  
  ...  
  {`{"摘录"："模型在这里写了另一个摘录"}]`}
  </Tabs.Tab>
  <Tabs.Tab>
   还有更多相关摘录吗？ 注意不要重复摘录。 还要确保摘录包含解释它们所需的所有相关上下文 - 换句话说，不要提取缺少重要上下文的小片段。
  </Tabs.Tab>
</Tabs>

